{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install --no-build-isolation --force-reinstall \\\n    \"boto3>=1.28.57\" \\\n    \"awscli>=1.29.57\" \\\n    \"botocore>=1.31.57\" --quiet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import boto3\nimport json","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"client = boto3.client('bedrock')\nruntime = boto3.client('bedrock-runtime')","metadata":{},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model_map = client.list_foundation_models()['modelSummaries']\nfor model in model_map:\n    print(model['modelName'])\n    print(model['modelId'])","metadata":{},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"Titan Text Large\n\namazon.titan-tg1-large\n\nTitan Image Generator G1\n\namazon.titan-image-generator-v1:0\n\nTitan Image Generator G1\n\namazon.titan-image-generator-v1\n\nTitan Text Embeddings v2\n\namazon.titan-embed-g1-text-02\n\nTitan Text G1 - Lite\n\namazon.titan-text-lite-v1:0:4k\n\nTitan Text G1 - Lite\n\namazon.titan-text-lite-v1\n\nTitan Text G1 - Express\n\namazon.titan-text-express-v1:0:8k\n\nTitan Text G1 - Express\n\namazon.titan-text-express-v1\n\nTitan Embeddings G1 - Text\n\namazon.titan-embed-text-v1:2:8k\n\nTitan Embeddings G1 - Text\n\namazon.titan-embed-text-v1\n\nTitan Multimodal Embeddings G1\n\namazon.titan-embed-image-v1:0\n\nTitan Multimodal Embeddings G1\n\namazon.titan-embed-image-v1\n\nSDXL 0.8\n\nstability.stable-diffusion-xl\n\nSDXL 0.8\n\nstability.stable-diffusion-xl-v0\n\nSDXL 1.0\n\nstability.stable-diffusion-xl-v1:0\n\nSDXL 1.0\n\nstability.stable-diffusion-xl-v1\n\nJ2 Grande Instruct\n\nai21.j2-grande-instruct\n\nJ2 Jumbo Instruct\n\nai21.j2-jumbo-instruct\n\nJurassic-2 Mid\n\nai21.j2-mid\n\nJurassic-2 Mid\n\nai21.j2-mid-v1\n\nJurassic-2 Ultra\n\nai21.j2-ultra\n\nJurassic-2 Ultra\n\nai21.j2-ultra-v1\n\nClaude Instant\n\nanthropic.claude-instant-v1:2:100k\n\nClaude Instant\n\nanthropic.claude-instant-v1\n\nClaude\n\nanthropic.claude-v2:0:18k\n\nClaude\n\nanthropic.claude-v2:0:100k\n\nClaude\n\nanthropic.claude-v2:1:18k\n\nClaude\n\nanthropic.claude-v2:1:200k\n\nClaude\n\nanthropic.claude-v2:1\n\nClaude\n\nanthropic.claude-v2\n\nClaude 3 Sonnet\n\nanthropic.claude-3-sonnet-20240229-v1:0:28k\n\nClaude 3 Sonnet\n\nanthropic.claude-3-sonnet-20240229-v1:0:200k\n\nClaude 3 Sonnet\n\nanthropic.claude-3-sonnet-20240229-v1:0\n\nClaude 3 Haiku\n\nanthropic.claude-3-haiku-20240307-v1:0:48k\n\nClaude 3 Haiku\n\nanthropic.claude-3-haiku-20240307-v1:0:200k\n\nClaude 3 Haiku\n\nanthropic.claude-3-haiku-20240307-v1:0\n\nCommand\n\ncohere.command-text-v14:7:4k\n\nCommand\n\ncohere.command-text-v14\n\nCommand Light\n\ncohere.command-light-text-v14:7:4k\n\nCommand Light\n\ncohere.command-light-text-v14\n\nEmbed English\n\ncohere.embed-english-v3:0:512\n\nEmbed English\n\ncohere.embed-english-v3\n\nEmbed Multilingual\n\ncohere.embed-multilingual-v3:0:512\n\nEmbed Multilingual\n\ncohere.embed-multilingual-v3\n\nLlama 2 Chat 13B\n\nmeta.llama2-13b-chat-v1:0:4k\n\nLlama 2 Chat 13B\n\nmeta.llama2-13b-chat-v1\n\nLlama 2 Chat 70B\n\nmeta.llama2-70b-chat-v1:0:4k\n\nLlama 2 Chat 70B\n\nmeta.llama2-70b-chat-v1\n\nLlama 2 13B\n\nmeta.llama2-13b-v1:0:4k\n\nLlama 2 13B\n\nmeta.llama2-13b-v1\n\nLlama 2 70B\n\nmeta.llama2-70b-v1:0:4k\n\nLlama 2 70B\n\nmeta.llama2-70b-v1\n\nMistral 7B Instruct\n\nmistral.mistral-7b-instruct-v0:2\n\nMixtral 8x7B Instruct\n\nmistral.mixtral-8x7b-instruct-v0:1\n\nMistral Large\n\nmistral.mistral-large-2402-v1:0\n"}]},{"cell_type":"markdown","source":"Inference using Claude","metadata":{}},{"cell_type":"code","source":"model_id = 'amazon.titan-tg1-large' \naccept = \"application/json\"\ncontentType = \"application/json\"","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"prompt_data = \"\"\"\nCommand: Write an email from Bob, Customer Service Manager, to the customer \"John Doe\" \nwho provided negative feedback on the service provided by our customer support \nengineer\"\"\"\n\n\nbody = json.dumps({\n    \"inputText\": prompt_data, \n    \"textGenerationConfig\":{\n        \"maxTokenCount\":4096,\n        \"stopSequences\":[],\n        \"temperature\":0,\n        \"topP\":0.9\n        }\n    }) ","metadata":{},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"response = runtime.invoke_model(body=body, modelId=model_id, accept=accept, contentType=contentType)","metadata":{},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"response_body = json.loads(response.get(\"body\").read())\nprint(response_body.get(\"completion\"))","metadata":{},"execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"None\n"}]}]}